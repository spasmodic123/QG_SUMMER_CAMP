# GNN图神经网络

![image-20230823104741039](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230823104741039.png)

通过**点**分析**边**的关系

![img](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/prediction_nodes_edges.26fadbcc.png)

通过**边**分析**点**的关系

![img](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/prediction_edges_nodes.e6796b8e.png)

通过**点**分析(**全局**,整个图)的关系

![img](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/prediction_nodes_edges_global.7a535eb8.png)

结合所有**点,边,全局**的关系分析整个图

![img](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/arch_graphnet.b229be6d.png)

## 意义

不仅可以处理结点的自身的关系,还可以处理不同节点之间的关系.比如社交网络,我们每一个人都有我们自身的特征,身高体重颜值性格等等,我们还会处理与他人的关系,我们喜欢谁,讨厌谁,亲朋好友的关系.

不仅考虑自身,也考虑与其他结点的联系,与attention有一定的相似之处

也适用于部分有标签,部分没有标签的数据,我们可以利用边的关系训练出点的特征(半监督学习)

 # 差分隐私

![差分隐私（三）- 指数，高斯，拉普拉斯机制](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/v2-d897dee39370f807dede0f08eb93f4bc_720w.jpg)

简单来说就是往数据里面加入一些噪声,使得攻击者获得的知识不会因为数据样本发生变化而变化.

比如:假设现在有一个婚恋数据库，2个单身8个已婚，只能查有多少人单身。刚开始的时候查询发现，2个人单身；现在张三跑去登记了自己婚姻状况，再一查，发现3个人单身。所以张三单身.

差分隐私做的,就是加入噪声后,原本两次查询出来的2和3,变成了随机数,而且相近的随机数,攻击者无法区分

## 公式理解

首先用到KL散度,是指当某分布q(x)被用于近似p(x)时的信息损失。![img](https://pic1.zhimg.com/v2-a44f38aca57b4583f630221bfcdba1b4_b.webp?consumer=ZHI_MENG)

也就是说，q(x)能在多大程度上表达p(x)所包含的信息，KL散度越大，表达效果越差。

差分隐私也是类似,我们计算加噪声后的数据用来近似原来的数据时的信息损失,Y是原来的数据,Z是加噪声后的数据

![image-20230726223431425](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230726223431425.png)

然后等式两边进行e指数运算,移项,变成下面差分隐私的定义

![image-20230726223550169](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230726223550169.png)

## 隐私损失

![image-20230804114559120](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230804114559120.png)

## 数值查询

### 拉普拉斯机制

![image-20230727090150832](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230727090150832.png)

f(D)表示的是查询函数,Y代表随机拉普拉斯噪声,M(D)表示最终返回结果

### 高斯机制

![image-20230727090217477](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230727090217477.png)

![image-20230727090150832](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230727090150832.png)

也可以写成上面的形式,拉普拉斯形式的Y是拉普拉斯分布的随机噪声;高斯机制的Y是高斯分布的随机噪声.

D^'^与D是兄弟数据集(只相差一个元素),表示查询上相差只相差一个元素

ε表示隐私预算，和噪声成负相关;     δ表示松弛项

**隐私损失被限制在 ε之内，同时也允许有很小的概率δ  打破这个限制**

## 非数值型查询

### 敏感度

敏感度代表的是,两个兄弟数据集D^'^与D(只相差一个元素),查询函数对于这两个数据集的最大变化范围.如果是查询数量,那么敏感度就是1,因为兄弟数据集只相差1个元素

![image-20230727091935337](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230727091935337.png)

q(D,R~i~)表示打分函数,结果就是输出结果R~i~的概率

与数值查询不同,数值查询是对一个确定的数值输出加入噪声实现差分隐私,而对于非数值型查询,用的是指数机制,它的输出是一个离散型的数据中的元素.

用到一个**指数机制**,查询的时候,返回的不是确定的**数值**结果,而是以一定的概率值返回结果.这个概率值由**打分函数**确定.得分高的输出概率高，得分低的输出概率低.

### 非数值型查询例子

假设现在有三种疾病，查询是为了得到人数最多的那种疾病，打分函数设置为疾病对应的人数

![1690420455238](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1690420455238.jpg)

加了差分隐私噪声之后,我们得到在查询者进行查询时,到底会返回给查询者哪一个疾病的概率

![1690421838178](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1690421838178.jpg)

比较不同的隐私预算ε的影响,得出结论,**隐私预算与可用性成正比,与隐私保护成反比**

## 隐私预算ε的理解

用典型的拉普拉斯机制距离,添加的噪声是期望是0,满足拉普拉斯分布![image-20230727095027215](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230727095027215.png)

这就意味着，如果噪声是**[独立同分布](https://www.zhihu.com/search?q=独立同分布&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1348363105})的**，那么我对多个噪声求平均，就在一定程度上可以使得噪声的值更接近0。在DP中，噪声接近0就意味着隐私保护程度的下降。

用日常生活例子距离,一个吸烟的人,我们要对这个吸烟的人收集数据,我们先不知道他是否吸烟,我们数据收集的协议就是

1. 数据收集者规定概率 p=0.6
2. 用户以概率 p发送真实值（ x=1 ），以概率 1−p 发送非真实值（ x=0 ）

根据差分隐私定义

![image-20230727095408130](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230727095408130.png)

隐私预算为ln1.5,

这是查询一次得到的隐私预算,如果查询两次![image-20230727100222686](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230727100222686.png)

隐私预算变为了ln1.5^2^

同样道理,如果可以一直查询下去，我们可以以任意的精度反推出x是0还是1。比如，在这个例子中，我问了你一百次，其中有65次你回答1，有35次你回答0，那么显然，用户的数据就是1了（不是说没可能是0，而是我们有很大很大的把握说是1.     攻击者可以通过这样的方法获得数据

如何防止这样的隐私泄露,一种很简单的想法就是,假设我根据我机制的设计，单个查询的隐私保护程度为 ϵ=1,然后我总的允许用户推断出的隐私保护程度为 ϵ=10，那也就意味着我允许用户**一共进行10次查询**。所以，我认为分配给这个查询者的隐私预算为 ϵ=10 ，然后这个用户每次进行一个查询，我就给他扣掉1

**其实关心的重点不是用户可以查询多少次,而是用户在查询多次后隐私保护水平还有多少!**所以隐私预算ϵ不是简单的采用减法,查询一次扣一次,现实情况更复杂,取决于我们设计噪声的方式,以及如何处理隐私预算ϵ