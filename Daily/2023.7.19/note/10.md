# Attention

## 为何要attention

对于简单的,短的文本,之前提到的encoder--decoder模型可以很好处理,但是一个句子很长,或者一个句子很复杂,即使是用来长期记忆的LSTM模型也会很难处理,这就需要引入attention.

attention的优点就是不受短时记忆的影响

还是以let's go 翻译成 西班牙语vamos. 作为例子

**attention就是给==解码器==的每一个步骤添加一个路径,这个路径可以直接访问==编码器==的的输出**,    ==一个解码器的输出可以对应多个编码器的输出==

给模型添加attention的方式并不唯一,这里介绍一种方式

## 具体过程

### 判断相似性

第一件事,是判断编码器的输出,和解码器的输入的相似性,通过余弦相似性.

之前提到过,一个单词可以用词向量表示,向量中的每一个元素就是该单词对于的权重.既然是向量,我们就可以利用两个向量之间的角度差值,计算相似性,具体方法如下

### 余弦相似性 

余弦相似性通过测量两个[向量](https://zh.wikipedia.org/wiki/向量)的夹角的[余弦](https://zh.wikipedia.org/wiki/余弦)值来度量它们之间的相似性。0度角的余弦值是1，而其他任何角度的余弦值都不大于1；并且其最小值是-1。从而两个向量之间的角度的余弦值确定两个向量是否大致指向相同的方向。两个向量有相同的指向时，余弦相似度的值为1；两个向量夹角为90°时，余弦相似度的值为0；两个向量指向完全相反的方向时，余弦相似度的值为-1。这结果是与向量的长度无关的，仅仅与向量的指向方向相关

![image-20230719094926106](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230719094926106.png)

**实际中,我们只计算分子部分**



![image-20230719103159370](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230719103159370.png)

在这里,第一步先计算英语的let's *(第一个编码器输出)*和 西班牙语<EOS>*(第一个解码器输出)*的相似性, 还计算go(第二个编码器输出) 和 <EOS>(第一个解码器输出)的相似性

![image-20230719103738061](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230719103738061.png)

我们可以获得let's的词向量和<EOS>的词向量,计算,得到-0.41

![image-20230719103929063](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230719103929063.png)

对于go 和 <EOS>一样道理,最终,我们算得,let's和<EOS>的相似性是-0.41,而go和<EOS>的相似性是0.01,后者大

**所以我们想要 go 能够对解码器的第一个输出产生更大的影响**

### softmax

先经过一个softmax函数,将相似性转换成概率分布

![image-20230719104551998](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230719104551998.png)

然后,我们利用概率,去按比例缩放编码器的输出,因为let's的编码器输出的向量是[-0.76,0.75],就把这个向量乘以0.4(概率)

go的编码器输出是[0.01.-0.01],乘以0.6(概率)

然后相加,最终得到的值,[-0.76,0.75]x0.4+[0.01.-0.01]x0.6我们称为<EOS>的attention的值,也就是[-0.3,0.3]  四舍五入之后

### 决定最终的输出词汇

将attention的值,和<EOS>的解码器的输入值,添加到全连接层

![image-20230719105504018](https://spasmodic.oss-cn-hangzhou.aliyuncs.com/image-20230719105504018.png)

attention是[-0.3,0.3],分别对应词向量第一个权重的attention,和第二个权重的attention,  0.9是<EOS>词向量的第一个权重,0.4是第二个权重

然后经过全连接层的计算,得到最终的预测单词

如果是不加attention的encoder--decoder模型,只输入0.9和0.4,也就是<EOS>的权重来计算最终概率,而加了attention之后,全连接层的输入维度从2变为了4

---

**以上的全部内容,就是给一个encoder--decoder模型添加attention模型的过程**

