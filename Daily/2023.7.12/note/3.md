# CNN

## 零填充

### 原因

**图像经过卷积之后,维度会减少**比如26\*26的图像,被3\*3的filter(滤波器)卷积之后变成了24\*24的图像  ,  如果被5\*5的滤波器卷积之后,变成了22\*22的图像(图片的边缘被卷积)

卷积后的图像维度公式

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689086474973.png"/>

原来的图像你n\*n,  滤波器f\*f

随着卷积层的增加, 图像会越来越小,并且可能会丢失有价值的,位于屏幕边缘的信息

### 定义及目的

在输入图像的边缘添加一层或多层像素均为0的边框,使得图像被卷积之后保持原来尺寸的大小

添加多少层取决于我们原始图片的大小和滤波器(filter)的大小

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689122266003.png"/>



## 最大池

### 定义

最大池化是一种操作类型，通常添加到单个卷积层**之后**的CNN中。当添加到模型中时，最大池化通过减少前一个卷积层输出中的像素数量来降低图像的维度。

### 与普通卷积的区别

#### 普通卷积

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/5c7cb9e5.gif"/>

在滤波器(filter)滑动的过程中,像素块可以重新重复

#### 最大池化

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689125170252.png"/>

滤波器(filter)在滑动过程中像素块不重复

### 例子

经过卷积操作的输出

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689125494677.png"/>

卷积操作的**输出**就是最大池化操作的**输入**,最大池化后的结果如下

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689125517402.png"/>

### 操作方法

最大集合的工作原理是这样的。我们定义某个 n x n 的区域作为最大池化操作的相应滤波器。本例中我们将使用 2 x 2。

我们定义一个步长**（stride）**，它决定了我们希望滤镜在图像上滑动时移动多少像素。

==步长决定滤波器一次滑动的单位==

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689125722260.png"/>

### 最大池作用

1. 降低计算负担,因为最大池化可以较大程度的降低图片像素,从而减少了参数数量

2. 防止过拟合

   ​       也许，它正在尝试识别MNIST数据集中的数字，因此它正在寻找边缘、曲线和圆圈之类的东西。从卷积层的输出来看，我们可以认为高估值像素是最活跃的像素。

   通过最大值池化，当我们对卷积输出的每个区域进行分析时，我们就能够挑选出最活跃的像素，并保留这些高值像素，同时丢弃那些不那么活跃的低值像素。**保留关键信息,去除相对不重要的信息**


### 可视化

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689127755507.png"/>



# tensor(张量)

**==张量是神经网络主要使用的数据结构==**(也是其他更加具体的概念的数学概括)        (是广义的概念)

## 为何要有tensor

tensor是一种**数据结构**,是一种神经网络易于使用且高效率使用的数据组织形式.好比做披萨,披萨是由面粉制成的,面粉好比数据,我们在制作披萨前不能直接使用面粉,而是要进行一定的加工,加点水,搅拌等等,数据也是一样道理.tensor就是数据加工后的样子

## 张量的具体实例

1. number(数字),array(数组),2d_array(2维数组)----计算科学领域

2. scalar(标量),vector(向量),martix(矩阵)----数学领域

   *其实数字和标量,数组和向量,2维数组和矩阵其实是同一个东西*

某一行中的两个实例具有相同的访问方式,也就是说具有相同的数据结构<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689129999951.png"/>

## 概念

张量就是一个泛化的概念,用一个张量就可以表达多个具体实例,只需要告诉**未知数n**,来确定我们的操作对象的维度<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689130546897.png"/>

## tensor的rank(秩),axis(轴),shape(形状)

### rank

张量的rank告诉我们访问一个在tensor中的元素需要几个索引(index)

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689131930261.png"/>

### axis

每一个axis代表一个特定的维度

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689131978396.png"/>

**张量的rank(秩)告诉我们张量有多少个axis(轴),(告诉我们有几个维度)，这些轴的长度引出了一个非常重要的概念，即张量的shape(形状)。**

### shape

张量的shape(形状)告诉我们每一个轴的长度

<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689132352246.png"/>



# tensor 解释CNN

## CNN输入<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689142448666.png"/>

CNN输入的形状长度通常为4。这意味着我们有一个具有四个轴的秩4张量(rank4 tensor)。张量形状中的每个索引代表一个特定的轴，每个索引的值给出了相应轴的长度。

张量的每个轴通常代表输入数据的某种现实世界或逻辑特征。如果我们了解了这些特征及其在张量中的轴位置，那么我们就可以很好地理解张量数据结构的整体。

### 像素点位置(heigh 和 width)

各一个数字,用了秩4张量(rank4 tensor)的**后两个维度**<img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689141863686.png"/>

### 颜色(color channel)

对与RGB图像,该维度的值一般为3;对于灰度图像( grayscale images),该值一般为1;

颜色的数据用一个值表示,占用了**从后往前数第3个维度**

### 批次(batch)

在向神经网络输送数据的时候,我们不是一次输送单个样本,也不是一次性全部样本(epoch),而是一次性输入一批样本(a batch)

这就是最大的维度,batch,从后往前数第4个维度

## NCHW vs NHWC vs CHWN

不同的的输入格式(format),N其实就是batch,C就是color channel,H就是height,W就是width

## 图片如何经过CNN

卷积会改变高度H,宽度尺寸W,以及通道数C。输出通道的数量根据卷积层中使用的**滤波器(filter)**数量而变化,不同的输出结果对应不同滤波器(filter)

由于参数改变,因为参数对应颜色通道,高度,和宽度,所以图片经过卷积之后会发生变化

### 例子

1. 原始输入,我们有两个滤波器(filter)

   <img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689143410620.png"/>

2. 第一个滤波器卷积之后

   <img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689143128787.png"/>

3. 第二个滤波器卷积之后

   <img src="https://spasmodic.oss-cn-hangzhou.aliyuncs.com/1689143137566.png"/>



## 特征图(feature map)

经过卷积层输出的图像被叫做特征图,一位特征图中包括了图像的特定特征,比如边缘,角落,还有更复杂的动物,人脸等等.

滤波器(filter)是模式识别器,不同的滤波器输出不同的特征图,比如上面 "例子" 的两张图片就是特征图
